{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p6BdOwa5E28A"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()"
      ],
      "metadata": {
        "id": "AUdrc5lKmdlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T7ivyotFIN7l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import ShuffleSplit"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.experimental.numpy.random.seed(seed)\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_all_seeds(420)"
      ],
      "metadata": {
        "id": "_3937hlekBYC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_accuracy_score(y_true, y_pred, k=1):\n",
        "    ranks = np.sum(y_pred >= y_pred[y_true == 1].reshape(-1, 1), axis=1)\n",
        "    return np.sum(ranks <= k) / ranks.shape[0]"
      ],
      "metadata": {
        "id": "BuE291mI2dTs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PD5Z29VMIT1M"
      },
      "outputs": [],
      "source": [
        "model_mn2 = MobileNetV2(\n",
        "    input_shape=None, alpha=1.0, include_top=True, weights='imagenet',\n",
        "    input_tensor=None, pooling=None, classes=1000\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FQ5jQ4yFIVmG"
      },
      "outputs": [],
      "source": [
        "model_mn2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymP-eapsIY-j"
      },
      "outputs": [],
      "source": [
        "layer_name = 'block_15_add'\n",
        "feature_extractor = Model(inputs=model_mn2.input, outputs=model_mn2.get_layer(layer_name).output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iKsTikqVIb6A"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6L7SisAUIdaB"
      },
      "outputs": [],
      "source": [
        "plants_names = []\n",
        "\n",
        "for plant in os.listdir('gdrive/MyDrive/flower_data/encoded/train'):\n",
        "    plants_names += [plant.split('.npy')[0]]\n",
        "\n",
        "plants_names.sort()\n",
        "plant_name_to_id = {plant: i for i, plant in enumerate(plants_names)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Lvmf5FWIrV7"
      },
      "outputs": [],
      "source": [
        "instances = {}\n",
        "labels = {}\n",
        "\n",
        "for set_kind in [\"test\", \"train\", \"val\"]:\n",
        "    X_per_class = []\n",
        "    y_per_class = []\n",
        "\n",
        "    for i, file in enumerate(os.listdir(f\"gdrive/MyDrive/flower_data/encoded/{set_kind}\")):\n",
        "        print(f\"\\r[{i}] {set_kind}/{file}\", end='')\n",
        "        plants_encoded = np.load(f\"gdrive/MyDrive/flower_data/encoded/{set_kind}/{file}\")\n",
        "        plant_name = file.split('.npy')[0]\n",
        "\n",
        "        X_per_class += [plants_encoded]\n",
        "        y_per_class += [plant_name_to_id[plant_name] for _ in range(plants_encoded.shape[0])]\n",
        "\n",
        "    instances[set_kind] = np.concatenate(X_per_class)\n",
        "    labels[set_kind] = np.array(y_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMrCatiSI9yt"
      },
      "outputs": [],
      "source": [
        "n_classes = len(plants_names)\n",
        "\n",
        "X_train = instances['train']\n",
        "y_train = np.eye(n_classes)[labels['train']]\n",
        "\n",
        "\n",
        "X_valid = instances['val']\n",
        "y_valid = np.eye(n_classes)[labels['val']]\n",
        "\n",
        "X_test = instances['test']\n",
        "y_test = np.eye(n_classes)[labels['test']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbC1jn4dJOyr"
      },
      "outputs": [],
      "source": [
        "input_layer = tf.keras.layers.Input(shape=[7, 7, 160], name=\"submodel_inputs\")\n",
        "intermediate = tf.keras.layers.Conv2D(filters=960, kernel_size=1, use_bias=False, name=\"block_16_expand\")(input_layer)\n",
        "intermediate = tf.keras.layers.BatchNormalization(name=\"block_16_expand_BN\")(intermediate)\n",
        "intermediate = tf.keras.layers.ReLU(name=\"block_16_expand_relu\")(intermediate)\n",
        "intermediate = tf.keras.layers.DepthwiseConv2D(\n",
        "    kernel_size=3, padding='same', use_bias=False, name=\"block_16_depthwise\")(intermediate)\n",
        "intermediate = tf.keras.layers.BatchNormalization(name=\"block_16_depthwise_BN\")(intermediate)\n",
        "intermediate = tf.keras.layers.ReLU(name=\"block_16_depthwise_relu\")(intermediate)\n",
        "intermediate = tf.keras.layers.Conv2D(filters=320, kernel_size=1, use_bias=False, name=\"block_16_project\")(intermediate)\n",
        "intermediate = tf.keras.layers.BatchNormalization(name=\"block_16_project_BN\")(intermediate)\n",
        "intermediate = tf.keras.layers.Conv2D(filters=1280, kernel_size=1, use_bias=False, name=\"Conv_1\")(intermediate)\n",
        "intermediate = tf.keras.layers.BatchNormalization(name=\"Conv_1_bn\")(intermediate)\n",
        "intermediate = tf.keras.layers.ReLU(name=\"out_relu\")(intermediate)\n",
        "intermediate = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling2d\")(intermediate)\n",
        "intermediate = tf.keras.layers.Dropout(rate=0.2, name=\"dropout\")(intermediate)\n",
        "output_layer = tf.keras.layers.Dense(\n",
        "    units=102, activation=\"softmax\", kernel_regularizer=keras.regularizers.l1(0.01), name=\"predictions\")(intermediate)\n",
        "\n",
        "model = Model(input_layer, output_layer)\n",
        "model.summary()\n",
        "\n",
        "for layer in model.layers:\n",
        "    if layer.name not in [\"submodel_inputs\", \"dropout\", \"predictions\"]:\n",
        "        layer.set_weights(model_mn2.get_layer(layer.name).get_weights())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqPu5IQcJaXW"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"nadam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8_cy2IEqJjUB"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HblJEgQKJlLe"
      },
      "outputs": [],
      "source": [
        "idx = np.arange(X_train.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "X_train_shuffled = X_train[idx]\n",
        "y_train_shuffled = y_train[idx]\n",
        "\n",
        "# Free some precious RAM\n",
        "del X_train\n",
        "del instances['train']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXfQx-rnJs5B"
      },
      "outputs": [],
      "source": [
        "checkpoint = ModelCheckpoint(filepath='model_mobilenetv2_regularized_oxford102',\n",
        "                             monitor='val_loss',\n",
        "                             verbose=1,\n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "\n",
        "history = model.fit(\n",
        "    X_train_shuffled, y_train_shuffled,\n",
        "    epochs=10,\n",
        "    validation_data=(X_valid, y_valid),\n",
        "    callbacks=[lr_scheduler, checkpoint]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLsVEZRaTEJZ"
      },
      "outputs": [],
      "source": [
        "model.save(\"model_mobilenetv2_regularized_oxford102\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uGnO4gXrIE0"
      },
      "outputs": [],
      "source": [
        "!zip -r model_mobilenetv2_regularized.zip model_mobilenetv2_regularized_oxford102/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.load_model('model_mobilenetv2_regularized_oxford102')\n",
        "print(\"Validation set accuracy\")\n",
        "preds_valid_1 = model(tf.reshape(X_valid, [-1, 7, 7, 160])).numpy()\n",
        "\n",
        "print(\"TOP 1\", top_k_accuracy_score(y_valid, preds_valid_1, k=1))\n",
        "print(\"TOP 5\", top_k_accuracy_score(y_valid, preds_valid_1, k=5))\n",
        "\n",
        "print(\"Test set\")\n",
        "preds_test_aug_1 = model(tf.reshape(X_test, [-1, 7, 7, 160])).numpy()\n",
        "\n",
        "print(\"TOP 1\", top_k_accuracy_score(y_test, preds_test_aug_1, k=1))\n",
        "print(\"TOP 5\", top_k_accuracy_score(y_test, preds_test_aug_1, k=5))"
      ],
      "metadata": {
        "id": "F0FYXnu10w_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oCbW2K9k1z7u"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}