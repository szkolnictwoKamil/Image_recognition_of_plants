{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vhm2daquoOE"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1cEpDIxZUY8"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_all_seeds(seed):\n",
        "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    tf.experimental.numpy.random.seed(seed)\n",
        "    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n",
        "    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "\n",
        "set_all_seeds(420)"
      ],
      "metadata": {
        "id": "i4lWoZpPkHMD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_k_accuracy_score(y_true, y_pred, k=1):\n",
        "    ranks = np.sum(y_pred >= y_pred[y_true == 1].reshape(-1, 1), axis=1)\n",
        "    return np.sum(ranks <= k) / ranks.shape[0]"
      ],
      "metadata": {
        "id": "URI5JxYV2nJd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SYSRQzC3d9Rb"
      },
      "source": [
        "model_mn2 = MobileNetV2(\n",
        "    input_shape=None, alpha=1.0, include_top=True, weights='imagenet',\n",
        "    input_tensor=None, pooling=None, classes=1000\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9O1I0iX6d9OB"
      },
      "source": [
        "model_mn2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PsL9-28pd9LW"
      },
      "source": [
        "layer_name = 'block_15_add'\n",
        "feature_extractor = Model(inputs=model_mn2.input, outputs=model_mn2.get_layer(layer_name).output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3V6PKNNSQVh"
      },
      "source": [
        "plants_names = []\n",
        "\n",
        "for plant in os.listdir('gdrive/MyDrive/flower_data/encoded/train'):\n",
        "    plants_names += [plant.split('.npy')[0]]\n",
        "\n",
        "plants_names.sort()\n",
        "plant_name_to_id = {plant: i for i, plant in enumerate(plants_names)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTViAm_uSQY7"
      },
      "source": [
        "instances = {}\n",
        "labels = {}\n",
        "\n",
        "for set_kind in [\"test\", \"train\", \"val\"]:\n",
        "    X_per_class = []\n",
        "    y_per_class = []\n",
        "\n",
        "    for i, file in enumerate(os.listdir(f\"gdrive/MyDrive/flower_data/encoded/{set_kind}\")):\n",
        "        print(f\"\\r[{i}] {set_kind}/{file}\", end='')\n",
        "        plants_encoded = np.load(f\"gdrive/MyDrive/flower_data/encoded/{set_kind}/{file}\")\n",
        "        plant_name = file.split('.npy')[0]\n",
        "\n",
        "        X_per_class += [plants_encoded.reshape([plants_encoded.shape[0], 49, 160])]\n",
        "        y_per_class += [plant_name_to_id[plant_name] for _ in range(plants_encoded.shape[0])]\n",
        "\n",
        "    instances[set_kind] = np.concatenate(X_per_class)\n",
        "    labels[set_kind] = np.array(y_per_class)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tC7x7lJSQTQ"
      },
      "source": [
        "n_classes = len(plants_names)\n",
        "\n",
        "X_train = instances['train']\n",
        "y_train = np.eye(n_classes)[labels['train']]\n",
        "\n",
        "X_valid = instances['val']\n",
        "y_valid = np.eye(n_classes)[labels['val']]\n",
        "\n",
        "X_test = instances['test']\n",
        "y_test = np.eye(n_classes)[labels['test']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lda_per_filter = [\n",
        "    LDA(n_components=5).fit(X_train[..., i], np.argmax(y_train, axis=1))\n",
        "    for i in range(X_train.shape[-1])\n",
        "]"
      ],
      "metadata": {
        "id": "bcg-qbz7obXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_means = np.array([filter.xbar_ for filter in lda_per_filter])\n",
        "all_means = all_means.T.reshape([1, 49, 160])\n",
        "\n",
        "all_components = np.array([filter.scalings_[:, :5] for filter in lda_per_filter])\n",
        "all_components = np.transpose(all_components, [1, 2, 0])"
      ],
      "metadata": {
        "id": "ouzh7ZKsobUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filterwise_dot = np.einsum('ij...,jk...->...ik', X_train - all_means, all_components)\n",
        "filterwise_dot = np.transpose(filterwise_dot, axes=[1, 2, 0])\n",
        "\n",
        "X_train_lda = filterwise_dot\n",
        "\n",
        "filterwise_dot = np.einsum('ij...,jk...->...ik', X_valid - all_means, all_components)\n",
        "filterwise_dot = np.transpose(filterwise_dot, axes=[1, 2, 0])\n",
        "\n",
        "X_valid_lda = filterwise_dot\n",
        "\n",
        "filterwise_dot = np.einsum('ij...,jk...->...ik', X_test - all_means, all_components)\n",
        "filterwise_dot = np.transpose(filterwise_dot, axes=[1, 2, 0])\n",
        "\n",
        "X_test_lda = filterwise_dot"
      ],
      "metadata": {
        "id": "nBwUdwU3rMR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "idx = np.arange(X_train_lda.shape[0])\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "X_train_lda_shuffled = X_train_lda[idx]\n",
        "y_train_shuffled = y_train[idx]\n",
        "\n",
        "X_train_lda_shuffled_flat = X_train_lda_shuffled.reshape(-1, 5 * 160)\n",
        "X_valid_lda_flat = X_valid_lda.reshape(-1, 5 * 160)\n",
        "X_test_aug_lda_flat = X_test_lda.reshape(-1, 5 * 160)"
      ],
      "metadata": {
        "id": "TAUPkEIxrjIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZCtIbZnlnrTo"
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=[5 * 160]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(256, kernel_initializer=\"lecun_normal\", use_bias=False),\n",
        "    keras.layers.ELU(),\n",
        "    keras.layers.Dropout(rate=0.15),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(480, kernel_initializer=\"lecun_normal\", use_bias=False),\n",
        "    keras.layers.ELU(),\n",
        "    keras.layers.Dropout(rate=0.25),\n",
        "    keras.layers.Dense(102, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"nadam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train_lda_shuffled_flat, y_train_shuffled,\n",
        "    epochs=10,\n",
        "    validation_data=(X_valid_lda_flat, y_valid),\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "P8fIIZqVlfBM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_lda_based\")\n",
        "!zip -r model_lda_basd.zip model_lda_based/"
      ],
      "metadata": {
        "id": "N2jT_xr9ueoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# model = keras.models.load_model('model_mobilenetv2_regularized_oxford102')\n",
        "print(\"Validation set accuracy\")\n",
        "preds_valid_1 = model(tf.reshape(X_valid, [-1, 7, 7, 160])).numpy()\n",
        "\n",
        "print(\"TOP 1\", top_k_accuracy_score(y_valid, preds_valid_1, k=1))\n",
        "print(\"TOP 5\", top_k_accuracy_score(y_valid, preds_valid_1, k=5))\n",
        "\n",
        "print(\"Test set\")\n",
        "preds_test_aug_1 = model(tf.reshape(X_test, [-1, 7, 7, 160])).numpy()\n",
        "\n",
        "print(\"TOP 1\", top_k_accuracy_score(y_test, preds_test_aug_1, k=1))\n",
        "print(\"TOP 5\", top_k_accuracy_score(y_test, preds_test_aug_1, k=5))"
      ],
      "metadata": {
        "id": "SwLBheYh3W2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras.models.Sequential([\n",
        "    keras.layers.Input(shape=[5, 160]),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.SeparableConv1D(filters=320, kernel_size=5, depth_multiplier=3),\n",
        "    keras.layers.ELU(),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dropout(rate=0.15),\n",
        "    keras.layers.BatchNormalization(),\n",
        "    keras.layers.Dense(480, kernel_initializer=\"lecun_normal\", use_bias=False),\n",
        "    keras.layers.ELU(),\n",
        "    keras.layers.Dropout(rate=0.25),\n",
        "    keras.layers.Dense(102, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=\"nadam\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=2)"
      ],
      "metadata": {
        "id": "Az4OIpRTmJDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "    X_train_lda_shuffled, y_train_shuffled,\n",
        "    epochs=10,\n",
        "    validation_data=(X_valid_lda, y_valid),\n",
        "    callbacks=[lr_scheduler]\n",
        ")\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "gAfjC4WMn1iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"model_lda_sepconv\")\n",
        "!zip -r model_lda_sepconv.zip model_lda_sepconv/"
      ],
      "metadata": {
        "id": "VnAuv0HArrbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E5L5x_XR4xZc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}